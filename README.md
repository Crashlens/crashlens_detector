# CrashLens

> Detect token waste patterns in GPT API logs. Offline, fast, and privacy-first.

## ğŸš€ What is CrashLens?

CrashLens is a CLI tool that scans Langfuse-style JSONL logs of GPT API usage and detects token waste patterns like retry loops, fallback storms, and inefficient GPT-4 usage. It estimates monthly cost waste and prints Slack-style or Markdown alerts to stdout. All processing is 100% local â€” no internet access, no SDK, no YAML input required.

## âš¡ Features

- **ğŸ” Detects token waste patterns**: Retry loops, fallback storms, and inefficient expensive model usage
- **ğŸ’° Cost estimation**: Supports GPT-4, GPT-3.5, and Claude models with accurate pricing
- **ğŸ“Š Multiple output formats**: Slack-style, Markdown, and cost summary modes
- **ğŸ”’ Privacy-first**: 100% local processing, no data leaves your machine
- **ğŸ“¥ Flexible input**: File, stdin pipe, or clipboard paste
- **ğŸ¯ Smart suggestions**: Recommends cheaper model alternatives
- **ğŸ“ˆ Monthly projections**: Estimates potential savings over time

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone <repository-url>
cd crashlens

# Install dependencies with Poetry
poetry install

# Run the tool
poetry run crashlens scan examples/demo-logs.jsonl
```

## ğŸ› ï¸ Usage

### Basic Commands

#### File Input
```bash
# Analyze a log file
crashlens scan logs.jsonl

# With custom pricing config
crashlens scan logs.jsonl --config custom-pricing.yaml

# Output in Markdown format
crashlens scan logs.jsonl --format markdown
```

#### Piped Input
```bash
# Pipe logs from another command
cat logs.jsonl | crashlens scan --stdin

# Process logs from a database export
mysql -e "SELECT * FROM logs" | crashlens scan --stdin

# Chain with other tools
grep "gpt-4" logs.jsonl | crashlens scan --stdin
```

#### Clipboard Input
```bash
# Copy logs to clipboard, then analyze
crashlens scan --paste

# Combine with other options
crashlens scan --paste --format markdown --summary
```

### Output Modes

#### 1. **Waste Detection Mode** (Default)
Detects and reports token waste patterns:
```bash
crashlens scan logs.jsonl
```

**Detects:**
- ğŸ”„ **Retry Loops**: Multiple calls with the same prompt
- ğŸ’ **Expensive Model Usage**: GPT-4/Claude for simple tasks
- âš¡ **Fallback Storms**: Multiple model switches in one trace

#### 2. **Cost Summary Mode**
Aggregates costs by route, model, and team:
```bash
crashlens scan logs.jsonl --summary
```

**Shows:**
- ğŸ’° Total cost breakdown
- ğŸ›£ï¸ Cost by API route
- ğŸ¤– Cost by model type
- ğŸ‘¥ Cost by team (if metadata available)
- ğŸ† Top 5 most expensive traces

#### 3. **Markdown Output**
Generates copy-paste ready reports:
```bash
crashlens scan logs.jsonl --format markdown
```

### Command Options

| Option | Description | Example |
|--------|-------------|---------|
| `log_file.jsonl` | Path to JSONL log file | `crashlens scan logs.jsonl` |
| `--stdin` | Read from stdin pipe | `cat logs.jsonl \| crashlens scan --stdin` |
| `--paste` | Read from clipboard | `crashlens scan --paste` |
| `--format` | Output format | `--format markdown` |
| `--summary` | Cost summary mode | `--summary` |
| `--config` | Custom pricing config | `--config pricing.yaml` |
| `--demo` | Use sample data | `--demo` |

### Input Data Format

CrashLens expects Langfuse-style JSONL logs with these fields:

```json
{
  "trace_id": "unique_trace_id",
  "timestamp": "2024-01-15T10:00:00Z",
  "model": "gpt-4",
  "prompt": "Your prompt text",
  "completion_tokens": 150,
  "prompt_tokens": 50,
  "cost": 0.003,
  "status": "success",
  "route": "/api/chat",
  "metadata": {
    "team": "frontend"
  }
}
```

**Required fields:** `trace_id`, `model`, `prompt`  
**Optional fields:** `cost`, `route`, `metadata.team`

## ğŸ§© Project Structure

```
crashlens/
â”œâ”€â”€ cli.py                      # Main Click CLI entrypoint
â”œâ”€â”€ detectors/                  # Token waste detection rules
â”‚   â”œâ”€â”€ retry_loops.py         # Detects repeated API calls
â”‚   â”œâ”€â”€ gpt4_short.py          # Detects expensive model overuse
â”‚   â””â”€â”€ fallback_storm.py      # Detects model switching patterns
â”œâ”€â”€ parsers/
â”‚   â””â”€â”€ langfuse.py            # JSONL loader, trace grouper by trace_id
â”œâ”€â”€ reporters/
â”‚   â”œâ”€â”€ slack_formatter.py     # Emoji-rich Slack-style output
â”‚   â”œâ”€â”€ markdown_formatter.py  # Copy-paste ready Markdown reports
â”‚   â””â”€â”€ summary_formatter.py   # Cost aggregation by route/model/team
â”œâ”€â”€ config/
â”‚   â””â”€â”€ pricing.yaml           # Model pricing configuration
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo-logs.jsonl        # Sample Langfuse-style logs
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_rules.py
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml
â””â”€â”€ .gitignore
```

## ğŸ”§ Configuration

### Model Pricing

Edit `config/pricing.yaml` to customize model costs and detection thresholds:

```yaml
models:
  gpt-4:
    input_cost_per_1k: 0.03
    output_cost_per_1k: 0.06
  claude-3-opus:
    input_cost_per_1k: 0.015
    output_cost_per_1k: 0.075

thresholds:
  retry_loop:
    max_retries: 3
    time_window_minutes: 5
  gpt4_short:
    min_tokens_for_gpt4: 100
    gpt4_cost_multiplier: 20.0
```

### Supported Models

- **GPT Models**: `gpt-4`, `gpt-4-32k`, `gpt-4-turbo`, `gpt-3.5-turbo`, `gpt-3.5-turbo-16k`
- **Claude Models**: `claude-3-opus`, `claude-3-sonnet`, `claude-3-haiku`, `claude-2.1`, `claude-2.0`, `claude-instant-1`

## ğŸ“‹ Examples

### Example 1: Basic Waste Detection
```bash
crashlens scan logs.jsonl
```
**Output:**
```
ğŸ”’ CrashLens runs 100% locally. No data leaves your system.
ğŸš¨ **CrashLens Token Waste Report**
==================================================
ğŸ’° **Total Potential Savings**: $4.87
ğŸ¯ **Wasted Tokens**: 83,407
ğŸ“Š **Issues Found**: 56

ğŸ”„ **Retry Loop** (4 issues)
  ğŸŸ¡ Retry loop detected: 5 calls for same prompt
     ğŸ’° Waste: $0.0015
     ğŸ¯ Tokens: 25
     ğŸ”„ Retries: 5
     â±ï¸  Time: 4.0 seconds
     ğŸ“„ Sample: What is 2+2?
     ğŸ”— Trace: trace_001
```

### Example 2: Cost Summary
```bash
crashlens scan logs.jsonl --summary
```
**Output:**
```
ğŸ”’ CrashLens runs 100% locally. No data leaves your system.
ğŸ“Š **CrashLens Cost Summary**
==================================================
ğŸ’° **Total Cost**: $0.2161
ğŸ¯ **Total Tokens**: 3,523
ğŸ“ˆ **Total Traces**: 8

ğŸ›£ï¸  **Cost by Route**
  /api/generate: $0.1200 (55.5%)
  /api/reports: $0.0480 (22.2%)
  /api/analyze: $0.0473 (21.9%)

ğŸ¤– **Cost by Model**
  gpt-4: $0.1683 (77.9%)
  claude-3-opus: $0.0450 (20.8%)
  claude-3-sonnet: $0.0023 (1.1%)
```

### Example 3: Markdown Report
```bash
crashlens scan logs.jsonl --format markdown
```
**Output:**
```markdown
ğŸ”’ CrashLens runs 100% locally. No data leaves your system.

# CrashLens Token Waste Report

## Summary

| Metric | Value |
|--------|-------|
| Total Potential Savings | $4.87 |
| Wasted Tokens | 83,407 |
| Issues Found | 56 |

## Retry Loop (4 issues)

### ğŸŸ¡ Issue #1
**Description**: Retry loop detected: 5 calls for same prompt
- **Waste Cost**: $0.0015
- **Waste Tokens**: 25
- **Retry Count**: 5
- **Time Span**: 4.0 seconds
- **Trace ID**: `trace_001`
```

## ğŸš€ Quick Start

1. **Install**: `poetry install`
2. **Test**: `crashlens scan examples/demo-logs.jsonl`
3. **Analyze your logs**: `crashlens scan your-logs.jsonl`
4. **Get summary**: `crashlens scan your-logs.jsonl --summary`
5. **Generate report**: `crashlens scan your-logs.jsonl --format markdown`

## ğŸ“ License

MIT License. See [LICENSE](LICENSE).

## ğŸ™ Acknowledgements

- Inspired by Langfuse, OpenAI, and the GPT developer community.

---

*CrashLens is a trust-first CLI tool designed to run offline and help you optimize your AI costs in 60 seconds.* 